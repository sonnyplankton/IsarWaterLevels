{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysing water levels of the river Isar\n",
    "\n",
    "In light of the recent flooding catastrophe with more then 170 dead, my interest sparked in monitoring and maybe predicting the waterlevels of the river in my hometown Munich, the river Isar.\n",
    "\n",
    "In this project you will get an idea how i refine my workflow and the identification of interesting data. I will also improve my skills in webscraping with beautiful soup and time series analysis.\n",
    "\n",
    "The project is structured in three main parts:\n",
    "\n",
    "1. Problem formulation and subject understanding\n",
    "2. Datasource identification and webscraping\n",
    "3. Data wrangling and time series analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Loading packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "now = datetime.today()\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "dirname = os.getcwd()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "#Script handling parameters\n",
    "scraping = False\n",
    "concatenating = True\n",
    "deleting_scraped_files = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Project goal and motivation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I started this project to get familiar with two skillsets in my data science learning journey:\n",
    "\n",
    "Tools and worflow technologies\n",
    "- Visual Studio Code\n",
    "- Github\n",
    "- Python scripting\n",
    "\n",
    "Data science subject\n",
    "- Time Series analysis\n",
    "- Time Series forecasting\n",
    "\n",
    "Also i see it as a portfolio project, highlighting my current skills in the above mentioned subjects, story telling and general Python programming. I will probably  \n",
    "use a lot ouf resources from practitioners, learners, professionals and amateures. For this reason i want to share my project and the isights i've gained with you and  \n",
    "i'm more then curios about your comments, suggestions and enhancements.\n",
    "\n",
    "Acknowledgements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Problem formulation and subject understanding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The isar is a 292,3 kilometer long river that originates in the very north of Austria. The river crosses the capital of bavaria Munich until it merges with the Donau river south of Deggendorf. [Source: wikipedia.com/isar]\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data collecting phase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Data Source identification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bavarian ministry for envoironment runs the so called \"Hochwassernachrichtendienst\" HND where the water levels of several rivers and lakes are provided. Additionally there are information on precipication and others.\n",
    "\n",
    "We focus on scraping the water levels first. The site is structured as follows\n",
    "\n",
    "    Basic Link:           https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen\n",
    "    Additional Parameter: ?days=0&hours=1\n",
    "\n",
    "We can address the levels per day for the last 30 days while 0 is today and 29 the oldest. The data is provided on an hourly interval from 0 to 23. For now, we don't need the most recent data, but this might change when upgrading to a more sophisticated scraping approach. At the moment we focus on getting a basic scrapping to work."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "#Web scraping properties\n",
    "link = \"https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen?days=0&hours=1\"\n",
    "basic_link = \"https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Web scraping"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Currently we scrap the full month of data and discarge the duplicates when we merge the DataFrames. This leads to a unneccessary long scraping time.  \n",
    "In order to reduce the scapring time we want to determine which days need to be scraped by comparing the difference between the recent data and the   \n",
    "current date."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "#list history file and read as df\n",
    "for file in os.listdir():\n",
    "    if 'isar_pegel_' in file:\n",
    "        hist_pegel = pd.read_csv(file)\n",
    "        last_scraped_datetime = pd.to_datetime(hist_pegel['Datum Zeit'][0], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        #determine the range of days to scrape\n",
    "        days_scrape  = [i for i in range(0,(now.day - last_scraped_datetime.day + 1))]\n",
    "    else:\n",
    "        #full scrape if no history available\n",
    "        hist_pegel = None\n",
    "        days_scrape  = [i for i in range(0,31)]\n",
    "    break\n",
    "\n",
    "#full hours to scrape\n",
    "hours_scrape = [i for i in range(0,24)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "#File handling properties\n",
    "von_string = str(date.today() - timedelta(days_scrape[-1]))\n",
    "bis_string = str(date.today())\n",
    "path = dirname + \"/ScrapingData/\"\n",
    "\n",
    "save_string = 'isar_pegel' + '_' + von_string +  '_bis_' + bis_string"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, pandas 'read_html' class is a very powerful tool to get html tabels quickly into a dataframe. We now automate this approach to scrape the full history of the water levels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "#Web scraping\n",
    "if scraping:\n",
    "\n",
    "    df_water_levels_scrape = pd.DataFrame()\n",
    "    \n",
    "    #add handling for most recent data\n",
    "    for day in days_scrape:\n",
    "        #when today, only scrape to current hour\n",
    "        if day == 0:\n",
    "\n",
    "            for hour in hours_scrape:\n",
    "                if hour <= (now.hour - 1):\n",
    "                    scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "                    water_level = pd.read_html(scrape_link)\n",
    "                    df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])\n",
    "                    \n",
    "        #when past days, scrape full hours\n",
    "        else:\n",
    "            for hour in hours_scrape:\n",
    "                scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "                water_level = pd.read_html(scrape_link)\n",
    "                df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])\n",
    "\n",
    "    df_water_levels_scrape['Datum Zeit'] = pd.to_datetime(df_water_levels_scrape['Datum Zeit'], format='%d.%m.%Y, %H:%M')\n",
    "    df_water_levels_scrape.to_csv((path + save_string + '.csv'), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "#concat files in the scraping folder into a single df\n",
    "\n",
    "if concatenating == True:\n",
    "       \n",
    "\n",
    "    #list files in the scraping folder and concat to single df\n",
    "    scraped_files       = os.listdir(path)\n",
    "    df_from_each_file   = (pd.read_csv(path + f) for f in scraped_files)\n",
    "    concatenated_df     = pd.concat(df_from_each_file, axis=0, ignore_index=True)\n",
    "\n",
    "    #sort and drop duplicates\n",
    "    concatenated_df     = concatenated_df.sort_values(by=['Datum Zeit'], ascending = False)\n",
    "    concatenated_df     = concatenated_df.drop_duplicates()\n",
    "\n",
    "    #concat hist and recent scraping\n",
    "    concatenated_df_2     = pd.concat([hist_pegel, concatenated_df], axis=0, ignore_index=True)\n",
    "    concatenated_df_2     = concatenated_df_2.sort_values(by=['Datum Zeit'], ascending = False)\n",
    "\n",
    "    #saving concatenated df to file\n",
    "    end_date            = concatenated_df_2['Datum Zeit'].iloc[0][:10]\n",
    "    start_date          = concatenated_df_2['Datum Zeit'].iloc[-1][:10]\n",
    "    save_string2        = 'isar_pegel' + '_' + start_date +  '_bis_' + end_date\n",
    "\n",
    "    os.remove(file)\n",
    "\n",
    "    concatenated_df_2   = concatenated_df_2.drop_duplicates()\n",
    "\n",
    "    concatenated_df_2.to_csv((save_string2 + '.csv'), index=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "#deleting scraped data\n",
    "if deleting_scraped_files == True:\n",
    "    for f in scraped_files:\n",
    "        os.remove(path + f)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are now able to automatically scrape and save the waterlevels, lets take a look at the date we get."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Data understanding phase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we can work with the data we need to understand the collected data first. I have separated this task into two main parts;\n",
    "\n",
    "- The quantitaive data understanding  \n",
    "Here we want to now how data data looks in the first place. Which variabels are in the data, how many observations, NaN values, data types, statistical information in numerical and unique values\n",
    "in categorical variables.  \n",
    "  \n",
    "  \n",
    "- The qualitative data understanding  \n",
    "Goal is to really understand the data from an domain point of view. How are different rivers, measuring points etc. are connected, what do cetrain variables mean.\n",
    "These questions are best answered by consulting the website (FAQ, reading material, documentation etc.) or interviewing experts in the field. These insights will\n",
    "help us further improve further analysis and forecasting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start with loading the latest data into a dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "#Load the complete csv to dataframe\n",
    "for file in os.listdir():\n",
    "        if 'isar_pegel_' in file:\n",
    "            waterlevel_hist = pd.read_csv(file)\n",
    "    \n",
    "        else:\n",
    "            waterlevel_hist = None\n",
    "    \n",
    "        break\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "waterlevel_hist.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Messstelle         Gewässer           Datum Zeit  \\\n",
       "0                Stegen            Amper  2021-09-15 21:00:00   \n",
       "1       Bad Tölz Brücke             Isar  2021-09-15 21:00:00   \n",
       "2  Oberfinning Seepegel  Windachspeicher  2021-09-15 21:00:00   \n",
       "3              Raisting             Rott  2021-09-15 21:00:00   \n",
       "4              Weilheim            Ammer  2021-09-15 21:00:00   \n",
       "\n",
       "   Wasser­stand [cm]  Änderung seit 2 Std. [cm] Abfluss [m³/s]  Melde­stufe  \\\n",
       "0                129                          0            258            0   \n",
       "1                 65                          0            ---            0   \n",
       "2              62509                          1            ---            0   \n",
       "3                 35                          0            022            0   \n",
       "4                 47                          1            977            0   \n",
       "\n",
       "  Jähr­lichkeit  Vorher­sage  \n",
       "0           ---          NaN  \n",
       "1           ---          NaN  \n",
       "2           ---          NaN  \n",
       "3           ---          NaN  \n",
       "4           ---          NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstelle</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Datum Zeit</th>\n",
       "      <th>Wasser­stand [cm]</th>\n",
       "      <th>Änderung seit 2 Std. [cm]</th>\n",
       "      <th>Abfluss [m³/s]</th>\n",
       "      <th>Melde­stufe</th>\n",
       "      <th>Jähr­lichkeit</th>\n",
       "      <th>Vorher­sage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stegen</td>\n",
       "      <td>Amper</td>\n",
       "      <td>2021-09-15 21:00:00</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Tölz Brücke</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-15 21:00:00</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oberfinning Seepegel</td>\n",
       "      <td>Windachspeicher</td>\n",
       "      <td>2021-09-15 21:00:00</td>\n",
       "      <td>62509</td>\n",
       "      <td>1</td>\n",
       "      <td>---</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raisting</td>\n",
       "      <td>Rott</td>\n",
       "      <td>2021-09-15 21:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>022</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weilheim</td>\n",
       "      <td>Ammer</td>\n",
       "      <td>2021-09-15 21:00:00</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>977</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "waterlevel_hist.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26280 entries, 0 to 26279\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Messstelle                 26280 non-null  object \n",
      " 1   Gewässer                   26280 non-null  object \n",
      " 2   Datum Zeit                 26280 non-null  object \n",
      " 3   Wasser­stand [cm]          26280 non-null  int64  \n",
      " 4   Änderung seit 2 Std. [cm]  26280 non-null  int64  \n",
      " 5   Abfluss [m³/s]             26280 non-null  object \n",
      " 6   Melde­stufe                26280 non-null  int64  \n",
      " 7   Jähr­lichkeit              26280 non-null  object \n",
      " 8   Vorher­sage                0 non-null      float64\n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "waterlevel_hist['Datum Zeit'] = pd.to_datetime(waterlevel_hist['Datum Zeit'], format='%Y-%m-%d %H:%M:%S')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "waterlevel_messtellen = waterlevel_hist['Messstelle'].unique()\n",
    "waterlevel_gewässer = waterlevel_hist['Gewässer'].unique()\n",
    "waterlevel_meldestufe = waterlevel_hist['Melde­stufe'].unique()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "print(waterlevel_messtellen)\n",
    "print(waterlevel_gewässer)\n",
    "print(waterlevel_meldestufe)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Stegen' 'Bad Tölz Brücke' 'Oberfinning Seepegel' 'Raisting' 'Weilheim'\n",
      " 'Peißenberg' 'Oberammergau' 'Inkofen' 'Fürstenfeldbruck' 'Sylvenstein'\n",
      " 'Leutstetten' 'Ampermoching' 'Oberfinning Speicherabgabe' 'Eching'\n",
      " 'Starnberg' 'Eschenlohe Brücke' 'Hohenkammer' 'Berg' 'Schlehdorf'\n",
      " 'Puppling' 'München' 'Freising' 'Landshut Birket' 'Landau' 'Plattling'\n",
      " 'Garmisch o. d. Partnachmündung' 'Garmisch u. d. Partnachmündung'\n",
      " 'Kochel' 'Beuerberg' 'Partenkirchen (alt)' 'Lenggries']\n",
      "['Amper' 'Isar' 'Windachspeicher' 'Rott' 'Ammer' 'Würm' 'Windach'\n",
      " 'Starnberger See' 'Loisach' 'Glonn' 'Sempt' 'Partnach' 'Ammersee']\n",
      "[0 4 1 3 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "waterlevel_hist[waterlevel_hist['Messstelle'] == 'Sylvenstein']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Messstelle Gewässer          Datum Zeit  Wasser­stand [cm]  \\\n",
       "9      Sylvenstein     Isar 2021-09-15 21:00:00                242   \n",
       "35     Sylvenstein     Isar 2021-09-15 20:00:00                242   \n",
       "83     Sylvenstein     Isar 2021-09-15 19:00:00                242   \n",
       "104    Sylvenstein     Isar 2021-09-15 18:00:00                242   \n",
       "130    Sylvenstein     Isar 2021-09-15 17:00:00                242   \n",
       "...            ...      ...                 ...                ...   \n",
       "26142  Sylvenstein     Isar 2021-08-13 04:00:00                257   \n",
       "26170  Sylvenstein     Isar 2021-08-13 03:00:00                257   \n",
       "26192  Sylvenstein     Isar 2021-08-13 02:00:00                257   \n",
       "26228  Sylvenstein     Isar 2021-08-13 01:00:00                257   \n",
       "26249  Sylvenstein     Isar 2021-08-13 00:00:00                258   \n",
       "\n",
       "       Änderung seit 2 Std. [cm] Abfluss [m³/s]  Melde­stufe Jähr­lichkeit  \\\n",
       "9                              0            116            0           ---   \n",
       "35                             0            116            0           ---   \n",
       "83                             0            116            0           ---   \n",
       "104                            0            116            0           ---   \n",
       "130                            0            116            0           ---   \n",
       "...                          ...            ...          ...           ...   \n",
       "26142                          0            201            0           ---   \n",
       "26170                          0            201            0           ---   \n",
       "26192                         -1            201            0           ---   \n",
       "26228                          0            201            0           ---   \n",
       "26249                          0            209            0           ---   \n",
       "\n",
       "       Vorher­sage  \n",
       "9              NaN  \n",
       "35             NaN  \n",
       "83             NaN  \n",
       "104            NaN  \n",
       "130            NaN  \n",
       "...            ...  \n",
       "26142          NaN  \n",
       "26170          NaN  \n",
       "26192          NaN  \n",
       "26228          NaN  \n",
       "26249          NaN  \n",
       "\n",
       "[817 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstelle</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Datum Zeit</th>\n",
       "      <th>Wasser­stand [cm]</th>\n",
       "      <th>Änderung seit 2 Std. [cm]</th>\n",
       "      <th>Abfluss [m³/s]</th>\n",
       "      <th>Melde­stufe</th>\n",
       "      <th>Jähr­lichkeit</th>\n",
       "      <th>Vorher­sage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-15 21:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-15 20:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-15 19:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-15 18:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-15 17:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26142</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-13 04:00:00</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26170</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-13 03:00:00</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26192</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-13 02:00:00</td>\n",
       "      <td>257</td>\n",
       "      <td>-1</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26228</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-13 01:00:00</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26249</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-13 00:00:00</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "e27770a5904c05f346266c3078d2f1c16671dbcdfa3785635894e45a4a43d3d6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
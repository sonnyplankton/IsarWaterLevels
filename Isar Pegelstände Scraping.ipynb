{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c259e29c",
   "metadata": {},
   "source": [
    "# Analysing water levels of the river Isar\n",
    "\n",
    "In light of the recent flooding catastrophe with more then 170 dead, my interest sparked in monitoring and maybe predicting the waterlevels of the river in my hometown Munich, the river Isar.\n",
    "\n",
    "In this project you will follow how i refine my workflow and the identification of interesting data data. I will also improve my skills in webscraping with beautiful soup and time series analysis.\n",
    "\n",
    "The project is structured in three main parts:\n",
    "\n",
    "1. Problem formulation and subject understanding\n",
    "2. Datasource identification and webscraping\n",
    "3. Data wrangling and time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc8196",
   "metadata": {},
   "source": [
    "## 0. Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4775d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22176e93",
   "metadata": {},
   "source": [
    "## 1. Problem formulation and subject understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d9e31",
   "metadata": {},
   "source": [
    "The isar is a 292,3 kilometer long river that originates in the very north of Austria. The river crosses the capital of bavaria Munich until it merges with the Donau river south of Deggendorf. [Source: wikipedia.com/isar]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd61508",
   "metadata": {},
   "source": [
    "## 2. Data Source identification and webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b4abb",
   "metadata": {},
   "source": [
    "The bavarian ministry for envoironment runs the so called \"Hochwassernachrichtendienst\" HND where the water levels of several rivers and lakes are provided. Additionally there are information on precipication and others.\n",
    "\n",
    "We focus on scraping the water levels first. The site is structured as follows\n",
    "\n",
    "    Basic Link:           https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen\n",
    "    Additional Parameter: ?days=0&hours=1\n",
    "\n",
    "We can address the levels per day for the last 30 days while 0 is today and 29 the oldest. The data is provided on an hourly interval from 0 to 23. For now, we don't need the most recent data, but this might change when upgrading to a more sophisticated scraping approach. At the moment we focus on getting a basic scrapping to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dac83f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create two lists for the days and hours we want to scrape.\n",
    "days_scrape  = [i for i in range(1,30)]\n",
    "hours_scrape = [i for i in range(0,24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1eda31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen?days=0&hours=1\"\n",
    "basic_link = \"https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen\"\n",
    "dfs = pd.read_html(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e7524",
   "metadata": {},
   "source": [
    "As you can see, pandas 'read_html' class is a very powerful tool to get html tabels quickly into a dataframe. We now automate this approach to scrap the full history of the water levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5da32be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_levels_scrape = pd.DataFrame()\n",
    "\n",
    "for day in days_scrape:\n",
    "    for hour in hours_scrape:\n",
    "        scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "        water_level = pd.read_html(scrape_link)\n",
    "        df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21d91acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_levels_scrape['Datum Zeit'] = pd.to_datetime(df_water_levels_scrape['Datum Zeit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0cd834ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22271 entries, 0 to 31\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Messstelle                 22271 non-null  object        \n",
      " 1   Gewässer                   22271 non-null  object        \n",
      " 2   Datum Zeit                 22271 non-null  datetime64[ns]\n",
      " 3   Wasser­stand [cm]          22271 non-null  int64         \n",
      " 4   Änderung seit 2 Std. [cm]  22271 non-null  int64         \n",
      " 5   Abfluss [m³/s]             22271 non-null  object        \n",
      " 6   Melde­stufe                22271 non-null  int64         \n",
      " 7   Jähr­lichkeit              22271 non-null  object        \n",
      " 8   Vorher­sage                0 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_water_levels_scrape.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae1d4859",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-d9e5880a9ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvon_datum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_water_levels_scrape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Datum Zeit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.date().strftime('%Y-%m-%d')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#bis_datum = df_water_levels_scrape['Datum Zeit'].max()#.date().strftime('%Y-%m-%d')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvon_datum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    890\u001b[0m             )\n\u001b[1;32m    891\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key of type tuple not found and not a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_water_levels_scrape.to_csv('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SQL Implementation Workbench"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "using_sql = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "#seen by https://realpython.com/python-sql-libraries/\n",
    "\n",
    "if using_sql == True:\n",
    "    \n",
    "    import sqlite3\n",
    "    from sqlite3 import Error\n",
    "\n",
    "    def create_connection(path):\n",
    "        connection = None\n",
    "        try:\n",
    "            connection = sqlite3.connect(path)\n",
    "            print(\"Connection to SQLite DB successful\")\n",
    "    \n",
    "        except Error as e:\n",
    "    \n",
    "            print(f\"The error '{e}' occurred\")\n",
    "\n",
    "        return connection\n",
    "\n",
    "    connection = create_connection('''E:\\\\sm_app.sqlite''')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connection to SQLite DB successful\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "connection."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Manipulate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "create_master_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS master_table (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  messstelle            TEXT NOT NULL,\n",
    "  gewässer              TEXT NOT NULL,\n",
    "  datetime              DATETIME,\n",
    "  wasserstand_cm       INT,\n",
    "  änderungen_2std_cm   INT,\n",
    "  abfluss_cm           INT,\n",
    "  meldestufe            TINYINT,\n",
    "  jährlichkeit          INT,\n",
    "  vorhersage            INT\n",
    ");\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "execute_query(connection, create_master_table)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query executed successfully\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "create_observations = \"\"\"\n",
    "INSERT INTO\n",
    "  master_table (messstelle, gewässer, datetime, wasserstand_cm, änderungen_2std_cm, abfluss_cm, meldestufe, jährlichkeit, vorhersage)\n",
    "VALUES\n",
    "  ('Engfurt', 'Isen', '2021-09-28 19:00:00', 79, 0, 153, 0,'---', 0)\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "execute_query(connection, create_observations)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The error '8 values for 9 columns' occurred\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "#Load the complete csv to dataframe\n",
    "for file in os.listdir():\n",
    "    if 'bay_river_pegel_' and 'csv' in file:\n",
    "        waterlevel_hist = pd.read_csv(file, parse_dates=True, na_values= '---')\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        waterlevel_hist = None\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "conda install sqlalchemy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/philippkron/.conda/envs/IsarAnalysis\n",
      "\n",
      "  added / updated specs:\n",
      "    - sqlalchemy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    greenlet-1.1.1             |   py39h9fcab8e_0          79 KB  conda-forge\n",
      "    sqlalchemy-1.4.25          |   py39h89e85a6_0         2.3 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  greenlet           conda-forge/osx-64::greenlet-1.1.1-py39h9fcab8e_0\n",
      "  sqlalchemy         conda-forge/osx-64::sqlalchemy-1.4.25-py39h89e85a6_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "greenlet-1.1.1       | 79 KB     | ##################################### | 100% \n",
      "sqlalchemy-1.4.25    | 2.3 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "from sqlalchemy import create_engine\n",
    "e = create_engine('''E:\\\\sm_app.sqlite''')  # pass your db url\n",
    "\n",
    "waterlevel_hist.to_sql(name='master_table', con=connection)\n",
    "#This allows you to use read_sql_table (which can only be used with SQLAlchemy):\n",
    "\n",
    "pd.read_sql_table(table_name='master_table', con=e)\n",
    "#         Date   AAPL     GE\n",
    "# 0 2009-01-02  89.95  14.76\n",
    "# 1 2009-01-05  93.75  14.38\n",
    "# 2 2009-01-06  92.20  14.58\n",
    "# 3 2009-01-07  90.21  13.93\n",
    "# 4 2009-01-08  91.88  13.95"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ArgumentError",
     "evalue": "Could not parse rfc1738 URL from string 'E:\\sm_app.sqlite'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/33/vf6wlxpx46v94qd6md3c23jh0000gn/T/ipykernel_11177/438902051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'''E:\\\\sm_app.sqlite'''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pass your db url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwaterlevel_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'master_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#This allows you to use read_sql_table (which can only be used with SQLAlchemy):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/IsarAnalysis/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     )\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/IsarAnalysis/lib/python3.9/site-packages/sqlalchemy/engine/create.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;31m# create url.URL object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiate_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/IsarAnalysis/lib/python3.9/site-packages/sqlalchemy/engine/url.py\u001b[0m in \u001b[0;36mmake_url\u001b[0;34m(name_or_url)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_rfc1738_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname_or_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/IsarAnalysis/lib/python3.9/site-packages/sqlalchemy/engine/url.py\u001b[0m in \u001b[0;36m_parse_rfc1738_args\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         raise exc.ArgumentError(\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0;34m\"Could not parse rfc1738 URL from string '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         )\n",
      "\u001b[0;31mArgumentError\u001b[0m: Could not parse rfc1738 URL from string 'E:\\sm_app.sqlite'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('IsarAnalysis': conda)"
  },
  "interpreter": {
   "hash": "6aefd68785b1005555596c47134b1c92bc3b88abc074e6046819eb23ac76f2b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
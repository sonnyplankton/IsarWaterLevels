{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysing water levels of the river Isar\n",
    "\n",
    "In light of the recent flooding catastrophe with more then 170 dead, my interest sparked in monitoring and maybe predicting the waterlevels of the river in my hometown Munich, the river Isar.\n",
    "\n",
    "In this project you will get an idea how i refine my workflow and the identification of interesting data. I will also improve my skills in webscraping with beautiful soup and time series analysis.\n",
    "\n",
    "The project is structured in three main parts:\n",
    "\n",
    "1. Problem formulation and subject understanding\n",
    "2. Datasource identification and webscraping\n",
    "3. Data wrangling and time series analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project goal and motivation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I started this project to get improve and expand two skillsets in my data science toolbox:\n",
    "\n",
    "Tools and workflow technologies\n",
    "- Visual Studio Code\n",
    "- Github\n",
    "- Python scripting\n",
    "\n",
    "Data science subject\n",
    "- Time Series analysis\n",
    "- Time Series forecasting\n",
    "\n",
    "Also i see it as a portfolio project, highlighting my current skills in the above mentioned subjects, story telling and general Python programming. I will probably  \n",
    "use a lot ouf resources from practitioners, learners, professionals and amateures. For this reason i want to share my project and the isights i've gained with you and  \n",
    "i'm more then curios about your comments, suggestions and enhancements.\n",
    "\n",
    "Acknowledgements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Loading packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "now = datetime.today()\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "dirname = os.getcwd()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "#Script handling parameters\n",
    "scraping = False\n",
    "concatenating = True\n",
    "deleting_scraped_files = False\n",
    "save_to = 'CSV'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Problem formulation and subject understanding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The isar is a 292,3 kilometer long river that originates in the very north of Austria. The river crosses the capital of bavaria Munich until it merges with the Donau river south of Deggendorf. [Source: wikipedia.com/isar]\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data collecting phase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Data Source identification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bavarian ministry for envoironment runs the so called \"Hochwassernachrichtendienst\" HND where the water levels of several rivers and lakes are provided. Additionally there are information on precipication and others.\n",
    "\n",
    "We focus on scraping the water levels first. The site is structured as follows\n",
    "\n",
    "    Basic Link:           https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen\n",
    "    Additional Parameter: ?days=0&hours=1\n",
    "\n",
    "We can address the levels per day for the last 30 days while 0 is today and 29 the oldest. The data is provided on an hourly interval from 0 to 23. For now, we don't need the most recent data, but this might change when upgrading to a more sophisticated scraping approach. At the moment we focus on getting a basic scrapping to work."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "#Web scraping properties\n",
    "#link = \"https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen?days=0&hours=1\"\n",
    "basic_link = \"https://www.hnd.bayern.de/pegel/tabellen\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Web scraping"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Currently we scrap the full month of data and discarge the duplicates when we merge the DataFrames. This leads to a unneccessary long scraping time.  \n",
    "In order to reduce the scapring time we want to determine which days need to be scraped by comparing the difference between the recent data and the   \n",
    "current date."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "#list history file and read as df\n",
    "for file in os.listdir():\n",
    "    if 'bay_river_pegel' in file:\n",
    "        hist_pegel = pd.read_csv(file)\n",
    "        last_scraped_datetime = pd.to_datetime(hist_pegel['Datum Zeit'][0], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        #determine the range of days to scrape\n",
    "        days_scrape  = [i for i in range(0,(now.day - last_scraped_datetime.day + 1))]\n",
    "    else:\n",
    "        #full scrape if no history available\n",
    "        hist_pegel = None\n",
    "        days_scrape  = [i for i in range(0,31)]\n",
    "\n",
    "\n",
    "#full hours to scrape\n",
    "hours_scrape = [i for i in range(0,24)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "#File handling properties\n",
    "von_string = str(date.today() - timedelta(days_scrape[-1]))\n",
    "bis_string = str(date.today() - timedelta(days_scrape[0]))\n",
    "path = dirname + \"/ScrapingData/\"\n",
    "\n",
    "save_string = 'bay_river_pegel' + '_' + von_string +  '_bis_' + bis_string"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, pandas 'read_html' class is a very powerful tool to get html tabels quickly into a dataframe. We now automate this approach to scrape the full history of the water levels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "#Web scraping\n",
    "if scraping:\n",
    "\n",
    "    df_water_levels_scrape = pd.DataFrame()\n",
    "    \n",
    "    #add handling for most recent data\n",
    "    for day in days_scrape:\n",
    "        #when today, only scrape to current hour\n",
    "        if day == 0:\n",
    "\n",
    "            for hour in hours_scrape:\n",
    "                if hour <= (now.hour - 1):\n",
    "                    scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "                    water_level = pd.read_html(scrape_link)\n",
    "                    df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])\n",
    "                    \n",
    "        #when past days, scrape full hours\n",
    "        else:\n",
    "            for hour in hours_scrape:\n",
    "                scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "                water_level = pd.read_html(scrape_link)\n",
    "                df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])\n",
    "\n",
    "    #df_water_levels_scrape['Datum Zeit'] = pd.to_datetime(df_water_levels_scrape['Datum Zeit'], format='%d.%m.%Y, %H:%M')\n",
    "    df_water_levels_scrape.to_csv((path + save_string + '.csv'), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "#concat files in the scraping folder into a single df\n",
    "\n",
    "if concatenating == True:\n",
    "    #list files in the scraping folder and concat to single df\n",
    "    scraped_files       = os.listdir(path)\n",
    "    df_from_each_file   = (pd.read_csv(path + f) for f in scraped_files)\n",
    "    concatenated_df     = pd.concat(df_from_each_file, axis=0, ignore_index=True)\n",
    "\n",
    "    #search for non available data and mark as nan. We do this step only on newly scraped data\n",
    "    missing_string = 'Derzeit leider keine aktuellen Daten vorhanden.'\n",
    "    concatenated_df = concatenated_df[concatenated_df != missing_string]\n",
    "    \n",
    "    #Subset because there are NaN in column \"Vorhersage\", which would drop everything\n",
    "    concatenated_df = concatenated_df.dropna(subset=['Wasser­stand [cm]'])\n",
    "\n",
    "    #sort and drop duplicates\n",
    "    concatenated_df     = concatenated_df.sort_values(by=['Datum Zeit'], ascending = True)\n",
    "    concatenated_df     = concatenated_df.drop_duplicates(['Messstelle','Datum Zeit'])\n",
    "\n",
    "    #concat hist and recent scraping\n",
    "    concatenated_df_2     = pd.concat([hist_pegel, concatenated_df], axis=0, ignore_index=True)\n",
    "    concatenated_df_2     = concatenated_df_2.sort_values(by=['Datum Zeit'], ascending = True)\n",
    "\n",
    "    #Clean up by dropping duplicates in observation point and datetime\n",
    "    concatenated_df_2   = concatenated_df_2.drop_duplicates(['Messstelle','Datum Zeit'])\n",
    "    concatenated_df_2['Datum Zeit'] = pd.to_datetime(concatenated_df_2['Datum Zeit'], format='%d.%m.%Y, %H:%M')\n",
    "    concatenated_df_2     = concatenated_df_2.sort_values(by=['Datum Zeit'], ascending = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since our scraping works as intended, we take the time to investigate the outcome. In theory, there should be 24 obersvations per day and oberservation point. We check this by saving an oberservation point to a dedicated DataFrame and group by date."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "waterlevel_sylvenstein = concatenated_df_2[concatenated_df_2['Messstelle'] == 'Sylvenstein']\n",
    "waterlevel_sylvenstein.groupby(by=waterlevel_sylvenstein['Datum Zeit'].dt.date).count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstelle</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Datum Zeit</th>\n",
       "      <th>Wasser­stand [cm]</th>\n",
       "      <th>Änderung seit 2 Std. [cm]</th>\n",
       "      <th>Abfluss [m³/s]</th>\n",
       "      <th>Melde­stufe</th>\n",
       "      <th>Jähr­lichkeit</th>\n",
       "      <th>Vorher­sage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum Zeit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-23</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-28</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-29</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-04</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-05</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-06</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-07</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-08</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-09</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-10</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-11</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-12</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-13</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-16</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-17</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-18</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-19</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-20</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Messstelle  Gewässer  Datum Zeit  Wasser­stand [cm]  \\\n",
       "Datum Zeit                                                        \n",
       "2021-08-23          24        24          24                 24   \n",
       "2021-08-24          24        24          24                 24   \n",
       "2021-08-25          24        24          24                 24   \n",
       "2021-08-26          24        24          24                 24   \n",
       "2021-08-27          24        24          24                 24   \n",
       "2021-08-28          24        24          24                 24   \n",
       "2021-08-29          24        24          24                 24   \n",
       "2021-08-30          24        24          24                 24   \n",
       "2021-08-31          24        24          24                 24   \n",
       "2021-09-01          24        24          24                 24   \n",
       "2021-09-02          24        24          24                 24   \n",
       "2021-09-03          24        24          24                 24   \n",
       "2021-09-04          24        24          24                 24   \n",
       "2021-09-05          24        24          24                 24   \n",
       "2021-09-06          24        24          24                 24   \n",
       "2021-09-07          24        24          24                 24   \n",
       "2021-09-08          24        24          24                 24   \n",
       "2021-09-09          24        24          24                 24   \n",
       "2021-09-10          24        24          24                 24   \n",
       "2021-09-11          24        24          24                 24   \n",
       "2021-09-12          24        24          24                 24   \n",
       "2021-09-13          24        24          24                 24   \n",
       "2021-09-14          24        24          24                 24   \n",
       "2021-09-15          24        24          24                 24   \n",
       "2021-09-16          24        24          24                 24   \n",
       "2021-09-17          24        24          24                 24   \n",
       "2021-09-18          24        24          24                 24   \n",
       "2021-09-19          24        24          24                 24   \n",
       "2021-09-20          24        24          24                 24   \n",
       "2021-09-21          24        24          24                 24   \n",
       "2021-09-22          20        20          20                 20   \n",
       "\n",
       "            Änderung seit 2 Std. [cm]  Abfluss [m³/s]  Melde­stufe  \\\n",
       "Datum Zeit                                                           \n",
       "2021-08-23                         24              24           24   \n",
       "2021-08-24                         24              24           24   \n",
       "2021-08-25                         24              24           24   \n",
       "2021-08-26                         24              24           24   \n",
       "2021-08-27                         24              24           24   \n",
       "2021-08-28                         24              24           24   \n",
       "2021-08-29                         24              24           24   \n",
       "2021-08-30                         24              24           24   \n",
       "2021-08-31                         24              24           24   \n",
       "2021-09-01                         24              24           24   \n",
       "2021-09-02                         24              24           24   \n",
       "2021-09-03                         24              24           24   \n",
       "2021-09-04                         24              24           24   \n",
       "2021-09-05                         24              24           24   \n",
       "2021-09-06                         24              24           24   \n",
       "2021-09-07                         24              24           24   \n",
       "2021-09-08                         24              24           24   \n",
       "2021-09-09                         24              24           24   \n",
       "2021-09-10                         24              24           24   \n",
       "2021-09-11                         24              24           24   \n",
       "2021-09-12                         24              24           24   \n",
       "2021-09-13                         24              24           24   \n",
       "2021-09-14                         24              24           24   \n",
       "2021-09-15                         24              24           24   \n",
       "2021-09-16                         24              24           24   \n",
       "2021-09-17                         24              24           24   \n",
       "2021-09-18                         24              24           24   \n",
       "2021-09-19                         24              24           24   \n",
       "2021-09-20                         24              24           24   \n",
       "2021-09-21                         24              24           24   \n",
       "2021-09-22                         20              20           20   \n",
       "\n",
       "            Jähr­lichkeit  Vorher­sage  \n",
       "Datum Zeit                              \n",
       "2021-08-23             24            0  \n",
       "2021-08-24             24            0  \n",
       "2021-08-25             24            0  \n",
       "2021-08-26             24            0  \n",
       "2021-08-27             24            0  \n",
       "2021-08-28             24            0  \n",
       "2021-08-29             24            0  \n",
       "2021-08-30             24            0  \n",
       "2021-08-31             24            0  \n",
       "2021-09-01             24            0  \n",
       "2021-09-02             24            0  \n",
       "2021-09-03             24            0  \n",
       "2021-09-04             24            0  \n",
       "2021-09-05             24            0  \n",
       "2021-09-06             24            0  \n",
       "2021-09-07             24            0  \n",
       "2021-09-08             24            0  \n",
       "2021-09-09             24            0  \n",
       "2021-09-10             24            0  \n",
       "2021-09-11             24            0  \n",
       "2021-09-12             24            0  \n",
       "2021-09-13             24            0  \n",
       "2021-09-14             24            0  \n",
       "2021-09-15             24            0  \n",
       "2021-09-16             24            0  \n",
       "2021-09-17             24            0  \n",
       "2021-09-18             24            0  \n",
       "2021-09-19             24            0  \n",
       "2021-09-20             24            0  \n",
       "2021-09-21             24            0  \n",
       "2021-09-22             20            0  "
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The scraped data is indeed what we have expected, exept for the last day, which is the current day and scraping is still a work in progress.\n",
    "\n",
    "Lastly we take a look at a complete day and see if we spot any mistakes whatsoever."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "waterlevel_sylvenstein"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstelle</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Datum Zeit</th>\n",
       "      <th>Wasser­stand [cm]</th>\n",
       "      <th>Änderung seit 2 Std. [cm]</th>\n",
       "      <th>Abfluss [m³/s]</th>\n",
       "      <th>Melde­stufe</th>\n",
       "      <th>Jähr­lichkeit</th>\n",
       "      <th>Vorher­sage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133568</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-22 19:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133318</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-22 18:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133078</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-22 17:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132826</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-22 16:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132574</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-09-22 15:00:00</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134606</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-23 04:00:00</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134584</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-23 03:00:00</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134328</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-23 02:00:00</td>\n",
       "      <td>256</td>\n",
       "      <td>+1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134074</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-23 01:00:00</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133591</th>\n",
       "      <td>Sylvenstein</td>\n",
       "      <td>Isar</td>\n",
       "      <td>2021-08-23 00:00:00</td>\n",
       "      <td>255</td>\n",
       "      <td>-1</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Messstelle Gewässer          Datum Zeit Wasser­stand [cm]  \\\n",
       "133568  Sylvenstein     Isar 2021-09-22 19:00:00               242   \n",
       "133318  Sylvenstein     Isar 2021-09-22 18:00:00               242   \n",
       "133078  Sylvenstein     Isar 2021-09-22 17:00:00               242   \n",
       "132826  Sylvenstein     Isar 2021-09-22 16:00:00               242   \n",
       "132574  Sylvenstein     Isar 2021-09-22 15:00:00               242   \n",
       "...             ...      ...                 ...               ...   \n",
       "134606  Sylvenstein     Isar 2021-08-23 04:00:00               256   \n",
       "134584  Sylvenstein     Isar 2021-08-23 03:00:00               256   \n",
       "134328  Sylvenstein     Isar 2021-08-23 02:00:00               256   \n",
       "134074  Sylvenstein     Isar 2021-08-23 01:00:00               256   \n",
       "133591  Sylvenstein     Isar 2021-08-23 00:00:00               255   \n",
       "\n",
       "       Änderung seit 2 Std. [cm] Abfluss [m³/s] Melde­stufe Jähr­lichkeit  \\\n",
       "133568                         0            116           0           ---   \n",
       "133318                         0            116           0           ---   \n",
       "133078                         0            116           0           ---   \n",
       "132826                         0            116           0           ---   \n",
       "132574                         0            116           0           ---   \n",
       "...                          ...            ...         ...           ...   \n",
       "134606                         0            192           0           ---   \n",
       "134584                         0            192           0           ---   \n",
       "134328                        +1            192           0           ---   \n",
       "134074                         0            192           0           ---   \n",
       "133591                        -1            184           0           ---   \n",
       "\n",
       "       Vorher­sage  \n",
       "133568         NaN  \n",
       "133318         NaN  \n",
       "133078         NaN  \n",
       "132826         NaN  \n",
       "132574         NaN  \n",
       "...            ...  \n",
       "134606         NaN  \n",
       "134584         NaN  \n",
       "134328         NaN  \n",
       "134074         NaN  \n",
       "133591         NaN  \n",
       "\n",
       "[740 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are happy with the results and save the dataframe to the disk."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Persistently save data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Obviously, we want to save our current efforts persistently to save the historical data we have put so much thought and effort in. We use .csv for now and also delete the last complete file to keep things tidy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "#delete current history file\n",
    "if 'bay_river_pegel' in file:\n",
    "    os.remove(file)\n",
    "\n",
    "#determine filename from content taking into account that values could be missing\n",
    "end_date            = concatenated_df_2['Datum Zeit'].iloc[0].strftime('%Y-%m-%d')\n",
    "start_date          = concatenated_df_2['Datum Zeit'].iloc[-1].strftime('%Y-%m-%d')\n",
    "save_string2        = 'bay_river_pegel' + '_' + start_date +  '_bis_' + end_date\n",
    "\n",
    "#saving concatenated df as .csv to disk\n",
    "concatenated_df_2.to_csv((save_string2 + '.csv'), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However with saving to .csv we loose the data type information from our DataFrame. For example, the datetime column would be loaded as object and not as datetime object.\n",
    "With the use of pythons pickle format (.pkl) these information is also saved to the file, allowing us to efficiently load the date in later steps. We take this opportunity\n",
    "to further refine our datatypes by looking at the current formats and see if we can optimize our data further."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "concatenated_df_2.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 188623 entries, 133554 to 133594\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   Messstelle                 188623 non-null  object        \n",
      " 1   Gewässer                   188623 non-null  object        \n",
      " 2   Datum Zeit                 188623 non-null  datetime64[ns]\n",
      " 3   Wasser­stand [cm]          188623 non-null  object        \n",
      " 4   Änderung seit 2 Std. [cm]  188623 non-null  object        \n",
      " 5   Abfluss [m³/s]             188623 non-null  object        \n",
      " 6   Melde­stufe                188623 non-null  object        \n",
      " 7   Jähr­lichkeit              188623 non-null  object        \n",
      " 8   Vorher­sage                0 non-null       object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "os.stat(save_string2 + '.csv')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33188, st_ino=37267953, st_dev=16777220, st_nlink=1, st_uid=501, st_gid=20, st_size=10822642, st_atime=1632335785, st_mtime=1632335785, st_ctime=1632335785)"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "#deleting scraped data\n",
    "if deleting_scraped_files == True:\n",
    "    for f in scraped_files:\n",
    "        os.remove(path + f)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are now able to automatically scrape and save the waterlevels, lets take a look at the date we get."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Data understanding phase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we can work with the data we need to understand the collected data first. I have separated this task into two main parts;\n",
    "\n",
    "- *The quantitaive data understanding*  \n",
    "Here we want to now how the data looks in the first place. Which variabels are in the data, how many observations, NaN values, data types, \n",
    "statistical information in numerical and unique values in categorical variables.    \n",
    "  \n",
    "  \n",
    "- *The qualitative data understanding*  \n",
    "Goal is to really understand the data from an domain point of view. How are different rivers, measuring points etc. are connected, what do cetrain variables mean.\n",
    "These questions are best answered by consulting the website (FAQ, reading material, documentation etc.) or interviewing experts in the field. These insights will\n",
    "help us further improve further analysis and forecasting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start bei loading the data in a DataFrame."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "#Load the complete csv to dataframe\n",
    "for file in os.listdir():\n",
    "    if 'isar_pegel_' in file:\n",
    "        waterlevel_hist = pd.read_csv(file)\n",
    "    \n",
    "    else:\n",
    "        waterlevel_hist = None\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "waterlevel_hist.head()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-aa9f02a6e3b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwaterlevel_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "waterlevel_hist.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27125 entries, 0 to 27124\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Messstelle                 27125 non-null  object \n",
      " 1   Gewässer                   27125 non-null  object \n",
      " 2   Datum Zeit                 27125 non-null  object \n",
      " 3   Wasser­stand [cm]          27125 non-null  int64  \n",
      " 4   Änderung seit 2 Std. [cm]  27125 non-null  int64  \n",
      " 5   Abfluss [m³/s]             27125 non-null  object \n",
      " 6   Melde­stufe                27125 non-null  int64  \n",
      " 7   Jähr­lichkeit              27125 non-null  object \n",
      " 8   Vorher­sage                0 non-null      float64\n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "waterlevel_hist['Datum Zeit'] = pd.to_datetime(waterlevel_hist['Datum Zeit'], format='%Y-%m-%d %H:%M:%S')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "waterlevel_messtellen = waterlevel_hist['Messstelle'].unique()\n",
    "waterlevel_gewässer = waterlevel_hist['Gewässer'].unique()\n",
    "waterlevel_meldestufe = waterlevel_hist['Melde­stufe'].unique()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(waterlevel_messtellen)\n",
    "print(waterlevel_gewässer)\n",
    "print(waterlevel_meldestufe)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Partenkirchen (alt)' 'Garmisch o. d. Partnachmündung' 'Fürstenfeldbruck'\n",
      " 'Oberammergau' 'Inkofen' 'Ampermoching' 'Stegen' 'Beuerberg' 'Peißenberg'\n",
      " 'Weilheim' 'Raisting' 'Oberfinning Seepegel' 'Kochel' 'Schlehdorf'\n",
      " 'Garmisch u. d. Partnachmündung' 'Oberfinning Speicherabgabe' 'Plattling'\n",
      " 'Sylvenstein' 'Leutstetten' 'Hohenkammer' 'Berg' 'Eschenlohe Brücke'\n",
      " 'Starnberg' 'Eching' 'Landau' 'Lenggries' 'Puppling' 'München' 'Freising'\n",
      " 'Landshut Birket' 'Bad Tölz Brücke']\n",
      "['Partnach' 'Loisach' 'Amper' 'Ammer' 'Rott' 'Windachspeicher' 'Windach'\n",
      " 'Isar' 'Würm' 'Glonn' 'Sempt' 'Starnberger See' 'Ammersee']\n",
      "[0 4 1 3 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "waterlevel_isar = waterlevel_hist[waterlevel_hist['Gewässer'] == 'Isar']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#datum_list = waterlevel_sylvenstein['Datum Zeit'].dt.floor('d').value_counts()()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "waterlevel_isar['Messstelle'].unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Plattling', 'Sylvenstein', 'Landau', 'Lenggries', 'Puppling',\n",
       "       'München', 'Freising', 'Landshut Birket', 'Bad Tölz Brücke'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "e27770a5904c05f346266c3078d2f1c16671dbcdfa3785635894e45a4a43d3d6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
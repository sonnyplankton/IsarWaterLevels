{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing water levels of the river Isar\n",
    "\n",
    "In light of the recent flooding catastrophe with more than 170 dead, my interest sparked in monitoring and maybe predicting the water levels of the river in my hometown Munich, the river Isar.\n",
    "\n",
    "In this project you will get an idea how I refine my workflow and the identification of interesting data. I will also improve my skills in web scraping with beautiful soup and time series analysis.\n",
    "\n",
    "The project is structured in three main parts:\n",
    "\n",
    "1. Problem formulation and subject understanding\n",
    "2. Data source identification and web scraping\n",
    "3. Data wrangling and time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project goal and motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started this project to get improve and expand two skill sets in my data science toolbox:\n",
    "\n",
    "Tools and workflow technologies\n",
    "- Visual Studio Code\n",
    "- Github\n",
    "- Python scripting\n",
    "\n",
    "Data science subject\n",
    "- Time Series analysis\n",
    "- Time Series forecasting\n",
    "\n",
    "Also, I see it as a portfolio project, highlighting my current skills in the above-mentioned subjects, story telling and general Python programming. I will probably  \n",
    "use a lot of resources from practitioners, learners, professionals and amateurs. For this reason I want to share my project and the insights I've gained with you and  \n",
    "I'm more than curious about your comments, suggestions and enhancements.\n",
    "\n",
    "Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "now = datetime.today()\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "dirname = os.getcwd()\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script handling parameters\n",
    "scraping = True\n",
    "concatenating = True\n",
    "deleting_scraped_files = False\n",
    "save_to = 'CSV'\n",
    "using_sql = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv date format\n",
    "format_1 = '%Y-%m-%d %H:%M:%S'\n",
    "#website date format\n",
    "format_2 = '%d.%m.%Y, %H:%M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem formulation and subject understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The isar is a 292,3 kilometer long river that originates in the very north of Austria. The river crosses the capital of bavaria Munich until it merges with the Donau river south of Deggendorf. [Source: wikipedia.com/isar]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data collecting phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Source identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bavarian ministry for envoironment runs the so called \"Hochwassernachrichtendienst\" HND where the water levels of several rivers and lakes are provided. Additionally there are information on precipication and others.\n",
    "\n",
    "We focus on scraping the water levels first. The site is structured as follows\n",
    "\n",
    "    Basic Link:           https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen\n",
    "    Additional Parameter: ?days=0&hours=1\n",
    "\n",
    "We can address the levels per day for the last 30 days while 0 is today and 29 the oldest. The data is provided on an hourly interval from 0 to 23. For now, we don't need the most recent data, but this might change when upgrading to a more sophisticated scraping approach. At the moment we focus on getting a basic scrapping to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web scraping properties\n",
    "#link = \"https://www.hnd.bayern.de/pegel/meldestufen/isar/tabellen?days=0&hours=1\"\n",
    "basic_link = \"https://www.hnd.bayern.de/pegel/tabellen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we scrap the full month of data and discarge the duplicates when we merge the DataFrames. This leads to a unneccessary long scraping time.  \n",
    "In order to reduce the scapring time we want to determine which days need to be scraped by comparing the difference between the recent data and the   \n",
    "current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list history file and read as df\n",
    "for file_name in os.listdir():\n",
    "    if 'bay_river_pegel' and '.csv' in file_name:\n",
    "        hist_pegel = pd.read_csv(file_name, parse_dates=True)\n",
    "        hist_pegel['datumzeit'] = pd.to_datetime(hist_pegel['datumzeit'], format='%Y-%m-%d %H:%M:%S')\n",
    "        last_scraped_datetime = hist_pegel['datumzeit'][0]\n",
    "        \n",
    "        #determine the range of days to scrape\n",
    "        days_scrape  = [i for i in range(0,((now - last_scraped_datetime).days + 1))]\n",
    "        break\n",
    "    else:\n",
    "        #full scrape if no history available\n",
    "        hist_pegel = None\n",
    "        days_scrape  = [i for i in range(0,31)]\n",
    "\n",
    "\n",
    "#full hours to scrape\n",
    "hours_scrape = [i for i in range(0,24)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File handling properties\n",
    "von_string = str(date.today() - timedelta(days_scrape[-1]))\n",
    "bis_string = str(date.today() - timedelta(days_scrape[0]))\n",
    "path = dirname + \"/ScrapingData/\"\n",
    "\n",
    "save_string = 'bay_river_pegel' + '_' + von_string +  '_bis_' + bis_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, pandas 'read_html' class is a very powerful tool to get html tabels quickly into a dataframe. We now automate this approach to scrape the full history of the water levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web scraping\n",
    "if scraping:\n",
    "    df_water_levels_scrape = pd.DataFrame()\n",
    "    \n",
    "    #add handling for most recent data\n",
    "    for day in days_scrape:\n",
    "        #when today, only scrape to current hour\n",
    "        if day == 0:\n",
    "\n",
    "            for hour in hours_scrape:\n",
    "                if hour <= (now.hour - 1):\n",
    "                    try:\n",
    "                        scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "                        water_level = pd.read_html(scrape_link)\n",
    "                        df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "        #when past days, scrape full hours\n",
    "        else:\n",
    "            for hour in hours_scrape:\n",
    "                try:\n",
    "                    scrape_link = basic_link + '?days=' + str(day) + '&hours=' + str(hour)\n",
    "                    water_level = pd.read_html(scrape_link)\n",
    "                    df_water_levels_scrape = df_water_levels_scrape.append(water_level[0])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "    #df_water_levels_scrape['Datum Zeit'] = pd.to_datetime(df_water_levels_scrape['Datum Zeit'], format='%d.%m.%Y, %H:%M')\n",
    "    df_water_levels_scrape.to_csv((path + save_string + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat files in the scraping folder into a single df\n",
    "\n",
    "if concatenating == True:\n",
    "    #list files in the scraping folder and concat to single df\n",
    "    scraped_files       = os.listdir(path)\n",
    "    df_from_each_file   = (pd.read_csv(path + f) for f in scraped_files)\n",
    "    concatenated_df     = pd.concat(df_from_each_file, axis=0, ignore_index=True)\n",
    "\n",
    "    #formatting of column names\n",
    "    concatenated_df.columns = concatenated_df.columns.str.replace(' ','')\n",
    "    concatenated_df.columns = concatenated_df.columns.str.replace('[^a-zA-ZäÄöÖüÜ0-9,]', '', regex=True)\n",
    "    concatenated_df.columns = concatenated_df.columns.str.lower()\n",
    "\n",
    "    #search for non available data and mark as nan. We do this step only on newly scraped data\n",
    "    #datetime formating from the websites date format\n",
    "    missing_string = 'Derzeit leider keine aktuellen Daten vorhanden.'\n",
    "    concatenated_df = concatenated_df[concatenated_df != missing_string]\n",
    "    concatenated_df['datumzeit'] = pd.to_datetime(concatenated_df['datumzeit'], format=format_2)\n",
    "    \n",
    "    #Subset because there are NaN in column \"Vorhersage\", which would drop everything\n",
    "    concatenated_df = concatenated_df.dropna(subset=['wasserstandcm'])\n",
    "\n",
    "  \n",
    "\n",
    "    #sort and drop duplicates\n",
    "    concatenated_df     = concatenated_df.sort_values(by=['datumzeit'], ascending = True)\n",
    "    concatenated_df     = concatenated_df.drop_duplicates(['messstelle','datumzeit'])\n",
    "\n",
    "    #concat hist and recent scraping\n",
    "    concatenated_df_2     = pd.concat([hist_pegel, concatenated_df], axis=0, ignore_index=True)\n",
    "    concatenated_df_2     = concatenated_df_2.sort_values(by=['datumzeit'], ascending = False)\n",
    "\n",
    "    #Clean up by dropping duplicates in observation point and datetime\n",
    "    concatenated_df_2   = concatenated_df_2.drop_duplicates(['messstelle','datumzeit'])\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['messstelle', 'gewässer', 'datumzeit', 'wasserstandcm',\n",
       "       'änderungseit2stdcm', 'abflussms', 'meldestufe', 'jährlichkeit',\n",
       "       'vorhersage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our scraping works as intended, we take the time to investigate the outcome. In theory, there should be 24 obersvations per day and oberservation point. We check this by saving an oberservation point to a dedicated DataFrame and group by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messstelle</th>\n",
       "      <th>gewässer</th>\n",
       "      <th>datumzeit</th>\n",
       "      <th>wasserstandcm</th>\n",
       "      <th>änderungseit2stdcm</th>\n",
       "      <th>abflussms</th>\n",
       "      <th>meldestufe</th>\n",
       "      <th>jährlichkeit</th>\n",
       "      <th>vorhersage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datumzeit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-23</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-26</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-27</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-28</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            messstelle  gewässer  datumzeit  wasserstandcm  \\\n",
       "datumzeit                                                    \n",
       "2021-08-23          24        24         24             24   \n",
       "2021-08-24          24        24         24             24   \n",
       "2021-08-25          24        24         24             24   \n",
       "2021-08-26          24        24         24             24   \n",
       "2021-08-27          24        24         24             24   \n",
       "...                ...       ...        ...            ...   \n",
       "2021-11-26          24        24         24             24   \n",
       "2021-11-27          24        24         24             24   \n",
       "2021-11-28          24        24         24             24   \n",
       "2021-11-29          24        24         24             24   \n",
       "2021-11-30          21        21         21             21   \n",
       "\n",
       "            änderungseit2stdcm  abflussms  meldestufe  jährlichkeit  \\\n",
       "datumzeit                                                             \n",
       "2021-08-23                  24         24          24             9   \n",
       "2021-08-24                  24         24          24            12   \n",
       "2021-08-25                  24         24          24            11   \n",
       "2021-08-26                  24         24          24            18   \n",
       "2021-08-27                  24         24          24             7   \n",
       "...                        ...        ...         ...           ...   \n",
       "2021-11-26                  24         24          24            24   \n",
       "2021-11-27                  24         24          24            24   \n",
       "2021-11-28                  24         24          24            24   \n",
       "2021-11-29                  24         24          24            24   \n",
       "2021-11-30                  21         21          21            21   \n",
       "\n",
       "            vorhersage  \n",
       "datumzeit               \n",
       "2021-08-23           0  \n",
       "2021-08-24           0  \n",
       "2021-08-25           0  \n",
       "2021-08-26           0  \n",
       "2021-08-27           0  \n",
       "...                ...  \n",
       "2021-11-26           0  \n",
       "2021-11-27           0  \n",
       "2021-11-28           0  \n",
       "2021-11-29           0  \n",
       "2021-11-30           0  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterlevel_sylvenstein = concatenated_df_2[concatenated_df_2['messstelle'] == 'Sylvenstein']\n",
    "waterlevel_sylvenstein.groupby(by=waterlevel_sylvenstein['datumzeit'].dt.date).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraped data is indeed what we have expected, exept for the last day, which is the current day and scraping is still a work in progress.\n",
    "\n",
    "Lastly we take a look at a complete day and see if we spot any mistakes whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2392 entries, 1112779 to 504124\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   messstelle          2392 non-null   object        \n",
      " 1   gewässer            2392 non-null   object        \n",
      " 2   datumzeit           2392 non-null   datetime64[ns]\n",
      " 3   wasserstandcm       2392 non-null   object        \n",
      " 4   änderungseit2stdcm  2392 non-null   object        \n",
      " 5   abflussms           2392 non-null   object        \n",
      " 6   meldestufe          2392 non-null   object        \n",
      " 7   jährlichkeit        1429 non-null   object        \n",
      " 8   vorhersage          0 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 186.9+ KB\n"
     ]
    }
   ],
   "source": [
    "waterlevel_sylvenstein.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are happy with the results and save the dataframe to the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistently save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we want to save our current efforts persistently to save the historical data we have put so much thought and effort in. We use .csv for now and also delete the last complete file to keep things tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete current history file\n",
    "if 'bay_river_pegel' in file_name:\n",
    "    os.remove(file_name)\n",
    "\n",
    "#determine filename from content taking into account that values could be missing\n",
    "end_date            = concatenated_df_2['datumzeit'].iloc[0].strftime('%Y-%m-%d')\n",
    "start_date          = concatenated_df_2['datumzeit'].iloc[-1].strftime('%Y-%m-%d')\n",
    "save_string2        = 'bay_river_pegel' + '_' + start_date +  '_bis_' + end_date\n",
    "\n",
    "#we identified two columns with no value and remove them from the dataet\n",
    "drop_columns        = ['jährlichkeit', 'vorhersage']\n",
    "concatenated_df_2.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "#we remove non number values to avoid saving data as object\n",
    "concatenated_df_2['wasserstandcm'] = concatenated_df_2['wasserstandcm'].replace('---', 0)\n",
    "concatenated_df_2['wasserstandcm'].astype(np.float64)\n",
    "concatenated_df_2['abflussms'] = concatenated_df_2['abflussms'].replace('---', 0)\n",
    "concatenated_df_2['abflussms'].astype(np.float64)\n",
    "concatenated_df_2['meldestufe'] = concatenated_df_2['meldestufe'].replace('---', 0)\n",
    "concatenated_df_2['meldestufe'].astype(np.int8)\n",
    "\n",
    "#saving concatenated df as .csv to disk\n",
    "concatenated_df_2.to_csv((save_string2 + '.csv'), index=False)\n",
    "#concatenated_df_2.to_pickle((save_string2 + '.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However with saving to .csv we loose the data type information from our DataFrame. For example, the datetime column would be loaded as object and not as datetime object.\n",
    "With the use of pythons pickle format (.pkl) these information is also saved to the file, allowing us to efficiently load the date in later steps. We take this opportunity\n",
    "to further refine our datatypes by looking at the current formats and see if we can optimize our data further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 608486 entries, 1112787 to 504539\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   messstelle          608486 non-null  object        \n",
      " 1   gewässer            608486 non-null  object        \n",
      " 2   datumzeit           608486 non-null  datetime64[ns]\n",
      " 3   wasserstandcm       608486 non-null  object        \n",
      " 4   änderungseit2stdcm  608486 non-null  object        \n",
      " 5   abflussms           608486 non-null  object        \n",
      " 6   meldestufe          608486 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "concatenated_df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting scraped data\n",
    "if deleting_scraped_files == True:\n",
    "    for f in scraped_files:\n",
    "        os.remove(path + f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are now able to automatically scrape and save the waterlevels, lets take a look at the date we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir():\n",
    "    if 'bay_river_pegel' and '.csv' in file_name:\n",
    "        river_data = pd.read_csv(file_name)\n",
    "        river_data['datumzeit'] = pd.to_datetime(river_data['datumzeit'], format='%Y-%m-%d %H:%M:%S')\n",
    "        #last_scraped_datetime = hist_pegel['datumzeit'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messstelle</th>\n",
       "      <th>gewässer</th>\n",
       "      <th>datumzeit</th>\n",
       "      <th>wasserstandcm</th>\n",
       "      <th>änderungseit2stdcm</th>\n",
       "      <th>abflussms</th>\n",
       "      <th>meldestufe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [messstelle, gewässer, datumzeit, wasserstandcm, änderungseit2stdcm, abflussms, meldestufe]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "river_data[river_data['datumzeit'] == 2021-10-16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 608486 entries, 0 to 608485\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   messstelle          608486 non-null  object        \n",
      " 1   gewässer            608486 non-null  object        \n",
      " 2   datumzeit           608486 non-null  datetime64[ns]\n",
      " 3   wasserstandcm       608486 non-null  int64         \n",
      " 4   änderungseit2stdcm  608486 non-null  int64         \n",
      " 5   abflussms           608486 non-null  float64       \n",
      " 6   meldestufe          608486 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(2)\n",
      "memory usage: 32.5+ MB\n"
     ]
    }
   ],
   "source": [
    "river_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "540a4d095e993f27b9008664929b11b54688fe09ae24a435bfc3df0f7da3dc19"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
